EPOCH 0
Time 1.61  min
Fold0 - Train loss: 147.7395055294037
Accuracy :
0.3145833333333333
Confusion matrix :
[[ 23  87  45]
 [ 14  67  16]
 [ 35 132  61]]
Accuracy low :
0.6229166666666667
Accuracy medium :
0.48125
Accuracy high :
0.525
Average accuracy :
0.5430555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.32      0.15      0.20       155
           1       0.23      0.69      0.35        97
           2       0.50      0.27      0.35       228

    accuracy                           0.31       480
   macro avg       0.35      0.37      0.30       480
weighted avg       0.39      0.31      0.30       480

Fold0 - Test loss: 16.420
Fold0 - Test accuracy: 31.46%
saved model runs\semrel_model/semrel_model_best

Time 8.51  min
Fold1 - Train loss: 295.2870088815689
Accuracy :
0.3625
Confusion matrix :
[[ 62  69  24]
 [ 28  47  22]
 [ 32 131  65]]
Accuracy low :
0.68125
Accuracy medium :
0.4791666666666667
Accuracy high :
0.5645833333333333
Average accuracy :
0.5750000000000001
Classification report :
              precision    recall  f1-score   support

           0       0.51      0.40      0.45       155
           1       0.19      0.48      0.27        97
           2       0.59      0.29      0.38       228

    accuracy                           0.36       480
   macro avg       0.43      0.39      0.37       480
weighted avg       0.48      0.36      0.38       480

Fold1 - Test loss: 16.370
Fold1 - Test accuracy: 36.25%
saved model runs\semrel_model/semrel_model_best

Time 11.98 min
Fold2 - Train loss: 442.70776760578156
Accuracy :
0.36041666666666666
Confusion matrix :
[[44 73 38]
 [18 54 25]
 [59 94 75]]
Accuracy low :
0.6083333333333333
Accuracy medium :
0.5625
Accuracy high :
0.55
Average accuracy :
0.5736111111111112
Classification report :
              precision    recall  f1-score   support

           0       0.36      0.28      0.32       155
           1       0.24      0.56      0.34        97
           2       0.54      0.33      0.41       228

    accuracy                           0.36       480
   macro avg       0.38      0.39      0.36       480
weighted avg       0.42      0.36      0.37       480

Fold2 - Test loss: 16.494
Fold2 - Test accuracy: 36.04%

Time 13.66 min
Fold3 - Train loss: 590.1098417043686
Accuracy :
0.42916666666666664
Confusion matrix :
[[78 36 41]
 [35 41 20]
 [56 86 87]]
Accuracy low :
0.65
Accuracy medium :
0.63125
Accuracy high :
0.5770833333333333
Average accuracy :
0.6194444444444445
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.50      0.48       155
           1       0.25      0.43      0.32        96
           2       0.59      0.38      0.46       229

    accuracy                           0.43       480
   macro avg       0.43      0.44      0.42       480
weighted avg       0.48      0.43      0.44       480

Fold3 - Test loss: 16.416
Fold3 - Test accuracy: 42.92%
saved model runs\semrel_model/semrel_model_best

Time 16.92 min
Fold4 - Train loss: 737.3698418140411
Accuracy :
0.41875
Confusion matrix :
[[81 43 31]
 [32 35 29]
 [53 91 85]]
Accuracy low :
0.66875
Accuracy medium :
0.59375
Accuracy high :
0.575
Average accuracy :
0.6124999999999999
Classification report :
              precision    recall  f1-score   support

           0       0.49      0.52      0.50       155
           1       0.21      0.36      0.26        96
           2       0.59      0.37      0.45       229

    accuracy                           0.42       480
   macro avg       0.43      0.42      0.41       480
weighted avg       0.48      0.42      0.43       480

Fold4 - Test loss: 16.398
Fold4 - Test accuracy: 41.88%

Time 18.67 min
Fold5 - Train loss: 884.5486001968384
Accuracy :
0.36666666666666664
Confusion matrix :
[[56 32 67]
 [47 23 26]
 [88 44 97]]
Accuracy low :
0.5125
Accuracy medium :
0.6895833333333333
Accuracy high :
0.53125
Average accuracy :
0.5777777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.29      0.36      0.32       155
           1       0.23      0.24      0.24        96
           2       0.51      0.42      0.46       229

    accuracy                           0.37       480
   macro avg       0.35      0.34      0.34       480
weighted avg       0.38      0.37      0.37       480

Fold5 - Test loss: 16.353
Fold5 - Test accuracy: 36.67%

Time 20.36 min
Fold6 - Train loss: 1031.8776304721832
Accuracy :
0.38125
Confusion matrix :
[[109  24  23]
 [ 46  32  18]
 [ 85 101  42]]
Accuracy low :
0.6291666666666667
Accuracy medium :
0.60625
Accuracy high :
0.5270833333333333
Average accuracy :
0.5875
Classification report :
              precision    recall  f1-score   support

           0       0.45      0.70      0.55       156
           1       0.20      0.33      0.25        96
           2       0.51      0.18      0.27       228

    accuracy                           0.38       480
   macro avg       0.39      0.41      0.36       480
weighted avg       0.43      0.38      0.36       480

Fold6 - Test loss: 16.477
Fold6 - Test accuracy: 38.12%

Time 22.05 min
Fold7 - Train loss: 1179.2767523527145
Accuracy :
0.325
Confusion matrix :
[[80 51 25]
 [46 27 23]
 [91 88 49]]
Accuracy low :
0.55625
Accuracy medium :
0.5666666666666667
Accuracy high :
0.5270833333333333
Average accuracy :
0.55
Classification report :
              precision    recall  f1-score   support

           0       0.37      0.51      0.43       156
           1       0.16      0.28      0.21        96
           2       0.51      0.21      0.30       228

    accuracy                           0.33       480
   macro avg       0.35      0.34      0.31       480
weighted avg       0.39      0.33      0.32       480

Fold7 - Test loss: 16.471
Fold7 - Test accuracy: 32.50%

Time 23.72 min
Fold8 - Train loss: 1326.5808635950089
Accuracy :
0.35625
Confusion matrix :
[[ 79  51  26]
 [ 36  43  17]
 [ 68 111  49]]
Accuracy low :
0.6229166666666667
Accuracy medium :
0.5520833333333334
Accuracy high :
0.5375
Average accuracy :
0.5708333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.51      0.47       156
           1       0.21      0.45      0.29        96
           2       0.53      0.21      0.31       228

    accuracy                           0.36       480
   macro avg       0.39      0.39      0.35       480
weighted avg       0.44      0.36      0.35       480

Fold8 - Test loss: 16.419
Fold8 - Test accuracy: 35.62%

Time 25.45 min
Fold9 - Train loss: 1473.694156050682
Accuracy :
0.36666666666666664
Confusion matrix :
[[108  24  24]
 [ 64  19  13]
 [113  66  49]]
Accuracy low :
0.53125
Accuracy medium :
0.6520833333333333
Accuracy high :
0.55
Average accuracy :
0.5777777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.38      0.69      0.49       156
           1       0.17      0.20      0.19        96
           2       0.57      0.21      0.31       228

    accuracy                           0.37       480
   macro avg       0.37      0.37      0.33       480
weighted avg       0.43      0.37      0.34       480

Fold9 - Test loss: 16.472
Fold9 - Test accuracy: 36.67%

EPOCH 1
Time 27.09 min
Fold0 - Train loss: 147.10376060009003
Accuracy :
0.3375
Confusion matrix :
[[ 27  98  30]
 [ 16  62  19]
 [ 35 120  73]]
Accuracy low :
0.6270833333333333
Accuracy medium :
0.47291666666666665
Accuracy high :
0.575
Average accuracy :
0.5583333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.35      0.17      0.23       155
           1       0.22      0.64      0.33        97
           2       0.60      0.32      0.42       228

    accuracy                           0.34       480
   macro avg       0.39      0.38      0.33       480
weighted avg       0.44      0.34      0.34       480

Fold0 - Test loss: 16.494
Fold0 - Test accuracy: 33.75%

Time 28.78 min
Fold1 - Train loss: 294.22108018398285
Accuracy :
0.35625
Confusion matrix :
[[ 55  58  42]
 [ 27  48  22]
 [ 35 125  68]]
Accuracy low :
0.6625
Accuracy medium :
0.5166666666666667
Accuracy high :
0.5333333333333333
Average accuracy :
0.5708333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.35      0.40       155
           1       0.21      0.49      0.29        97
           2       0.52      0.30      0.38       228

    accuracy                           0.36       480
   macro avg       0.40      0.38      0.36       480
weighted avg       0.44      0.36      0.37       480

Fold1 - Test loss: 16.420
Fold1 - Test accuracy: 35.62%

Time 30.50 min
Fold2 - Train loss: 441.53872299194336
Accuracy :
0.3458333333333333
Confusion matrix :
[[48 63 44]
 [29 33 35]
 [73 70 85]]
Accuracy low :
0.5645833333333333
Accuracy medium :
0.5895833333333333
Accuracy high :
0.5375
Average accuracy :
0.563888888888889
Classification report :
              precision    recall  f1-score   support

           0       0.32      0.31      0.31       155
           1       0.20      0.34      0.25        97
           2       0.52      0.37      0.43       228

    accuracy                           0.35       480
   macro avg       0.35      0.34      0.33       480
weighted avg       0.39      0.35      0.36       480

Fold2 - Test loss: 16.483
Fold2 - Test accuracy: 34.58%

Time 32.20 min
Fold3 - Train loss: 588.941682934761
Accuracy :
0.45208333333333334
Confusion matrix :
[[ 78  31  46]
 [ 35  34  27]
 [ 53  71 105]]
Accuracy low :
0.65625
Accuracy medium :
0.6583333333333333
Accuracy high :
0.5895833333333333
Average accuracy :
0.6347222222222222
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.50      0.49       155
           1       0.25      0.35      0.29        96
           2       0.59      0.46      0.52       229

    accuracy                           0.45       480
   macro avg       0.44      0.44      0.43       480
weighted avg       0.48      0.45      0.46       480

Fold3 - Test loss: 16.400
Fold3 - Test accuracy: 45.21%
saved model runs\semrel_model/semrel_model_best

Time 35.28 min
Fold4 - Train loss: 736.1795345544815
Accuracy :
0.44375
Confusion matrix :
[[ 54  41  60]
 [ 30  28  38]
 [ 32  66 131]]
Accuracy low :
0.6604166666666667
Accuracy medium :
0.6354166666666666
Accuracy high :
0.5916666666666667
Average accuracy :
0.6291666666666668
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.35      0.40       155
           1       0.21      0.29      0.24        96
           2       0.57      0.57      0.57       229

    accuracy                           0.44       480
   macro avg       0.41      0.40      0.40       480
weighted avg       0.46      0.44      0.45       480

Fold4 - Test loss: 16.370
Fold4 - Test accuracy: 44.38%

Time 36.99 min
Fold5 - Train loss: 883.1413035392761
Accuracy :
0.37083333333333335
Confusion matrix :
[[101  23  31]
 [ 62   9  25]
 [127  34  68]]
Accuracy low :
0.49375
Accuracy medium :
0.7
Accuracy high :
0.5479166666666667
Average accuracy :
0.5805555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.35      0.65      0.45       155
           1       0.14      0.09      0.11        96
           2       0.55      0.30      0.39       229

    accuracy                           0.37       480
   macro avg       0.34      0.35      0.32       480
weighted avg       0.40      0.37      0.35       480

Fold5 - Test loss: 16.463
Fold5 - Test accuracy: 37.08%

Time 38.67 min
Fold6 - Train loss: 1030.3970795869827
Accuracy :
0.4395833333333333
Confusion matrix :
[[116  10  30]
 [ 54  10  32]
 [112  31  85]]
Accuracy low :
0.5708333333333333
Accuracy medium :
0.7354166666666667
Accuracy high :
0.5729166666666666
Average accuracy :
0.6263888888888888
Classification report :
              precision    recall  f1-score   support

           0       0.41      0.74      0.53       156
           1       0.20      0.10      0.14        96
           2       0.58      0.37      0.45       228

    accuracy                           0.44       480
   macro avg       0.40      0.41      0.37       480
weighted avg       0.45      0.44      0.41       480

Fold6 - Test loss: 16.456
Fold6 - Test accuracy: 43.96%

Time 40.36 min
Fold7 - Train loss: 1177.4756786823273
Accuracy :
0.39166666666666666
Confusion matrix :
[[ 99  16  41]
 [ 58  11  27]
 [121  29  78]]
Accuracy low :
0.5083333333333333
Accuracy medium :
0.7291666666666666
Accuracy high :
0.5458333333333333
Average accuracy :
0.5944444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.36      0.63      0.46       156
           1       0.20      0.11      0.14        96
           2       0.53      0.34      0.42       228

    accuracy                           0.39       480
   macro avg       0.36      0.36      0.34       480
weighted avg       0.41      0.39      0.38       480

Fold7 - Test loss: 16.464
Fold7 - Test accuracy: 39.17%

Time 42.05 min
Fold8 - Train loss: 1324.5712999105453
Accuracy :
0.33125
Confusion matrix :
[[ 81  53  22]
 [ 38  45  13]
 [ 73 122  33]]
Accuracy low :
0.6125
Accuracy medium :
0.5291666666666667
Accuracy high :
0.5208333333333334
Average accuracy :
0.5541666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.42      0.52      0.47       156
           1       0.20      0.47      0.28        96
           2       0.49      0.14      0.22       228

    accuracy                           0.33       480
   macro avg       0.37      0.38      0.32       480
weighted avg       0.41      0.33      0.31       480

Fold8 - Test loss: 16.409
Fold8 - Test accuracy: 33.12%

Time 43.76 min
Fold9 - Train loss: 1471.4871658086777
Accuracy :
0.3854166666666667
Confusion matrix :
[[79 34 43]
 [52 17 27]
 [74 65 89]]
Accuracy low :
0.5770833333333333
Accuracy medium :
0.6291666666666667
Accuracy high :
0.5645833333333333
Average accuracy :
0.5902777777777777
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.51      0.44       156
           1       0.15      0.18      0.16        96
           2       0.56      0.39      0.46       228

    accuracy                           0.39       480
   macro avg       0.36      0.36      0.35       480
weighted avg       0.42      0.39      0.39       480

Fold9 - Test loss: 16.466
Fold9 - Test accuracy: 38.54%

EPOCH 2
Time 45.41 min
Fold0 - Train loss: 147.14739346504211
Accuracy :
0.39166666666666666
Confusion matrix :
[[59 57 39]
 [34 39 24]
 [66 72 90]]
Accuracy low :
0.5916666666666667
Accuracy medium :
0.6104166666666667
Accuracy high :
0.58125
Average accuracy :
0.5944444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.37      0.38      0.38       155
           1       0.23      0.40      0.29        97
           2       0.59      0.39      0.47       228

    accuracy                           0.39       480
   macro avg       0.40      0.39      0.38       480
weighted avg       0.45      0.39      0.41       480

Fold0 - Test loss: 16.406
Fold0 - Test accuracy: 39.17%

Time 47.10 min
Fold1 - Train loss: 293.96641290187836
Accuracy :
0.36041666666666666
Confusion matrix :
[[57 55 43]
 [33 33 31]
 [54 91 83]]
Accuracy low :
0.6145833333333334
Accuracy medium :
0.5625
Accuracy high :
0.54375
Average accuracy :
0.5736111111111112
Classification report :
              precision    recall  f1-score   support

           0       0.40      0.37      0.38       155
           1       0.18      0.34      0.24        97
           2       0.53      0.36      0.43       228

    accuracy                           0.36       480
   macro avg       0.37      0.36      0.35       480
weighted avg       0.42      0.36      0.38       480

Fold1 - Test loss: 16.475
Fold1 - Test accuracy: 36.04%

Time 48.81 min
Fold2 - Train loss: 440.81999826431274
Accuracy :
0.375
Confusion matrix :
[[ 56  40  59]
 [ 28  20  49]
 [ 70  54 104]]
Accuracy low :
0.5895833333333333
Accuracy medium :
0.64375
Accuracy high :
0.5166666666666667
Average accuracy :
0.5833333333333334
Classification report :
              precision    recall  f1-score   support

           0       0.36      0.36      0.36       155
           1       0.18      0.21      0.19        97
           2       0.49      0.46      0.47       228

    accuracy                           0.38       480
   macro avg       0.34      0.34      0.34       480
weighted avg       0.39      0.38      0.38       480

Fold2 - Test loss: 16.543
Fold2 - Test accuracy: 37.50%

Time 50.54 min
Fold3 - Train loss: 587.7359653711319
Accuracy :
0.4625
Confusion matrix :
[[ 77  24  54]
 [ 34  30  32]
 [ 52  62 115]]
Accuracy low :
0.6583333333333333
Accuracy medium :
0.6833333333333333
Accuracy high :
0.5833333333333334
Average accuracy :
0.6416666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.50      0.48       155
           1       0.26      0.31      0.28        96
           2       0.57      0.50      0.53       229

    accuracy                           0.46       480
   macro avg       0.43      0.44      0.43       480
weighted avg       0.48      0.46      0.47       480

Fold3 - Test loss: 16.417
Fold3 - Test accuracy: 46.25%
saved model runs\semrel_model/semrel_model_best

Time 53.17 min
Fold4 - Train loss: 735.0415056943893
Accuracy :
0.4666666666666667
Confusion matrix :
[[126   9  20]
 [ 60  17  19]
 [ 89  59  81]]
Accuracy low :
0.6291666666666667
Accuracy medium :
0.69375
Accuracy high :
0.6104166666666667
Average accuracy :
0.6444444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.81      0.59       155
           1       0.20      0.18      0.19        96
           2       0.68      0.35      0.46       229

    accuracy                           0.47       480
   macro avg       0.44      0.45      0.41       480
weighted avg       0.51      0.47      0.45       480

Fold4 - Test loss: 16.462
Fold4 - Test accuracy: 46.67%
saved model runs\semrel_model/semrel_model_best

Time 55.78 min
Fold5 - Train loss: 882.1758052110672
Accuracy :
0.4083333333333333
Confusion matrix :
[[ 35  59  61]
 [ 15  29  52]
 [ 32  65 132]]
Accuracy low :
0.6520833333333333
Accuracy medium :
0.6020833333333333
Accuracy high :
0.5625
Average accuracy :
0.6055555555555555
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.23      0.30       155
           1       0.19      0.30      0.23        96
           2       0.54      0.58      0.56       229

    accuracy                           0.41       480
   macro avg       0.39      0.37      0.36       480
weighted avg       0.43      0.41      0.41       480

Fold5 - Test loss: 16.466
Fold5 - Test accuracy: 40.83%

Time 57.45 min
Fold6 - Train loss: 1029.3291057348251
Accuracy :
0.40208333333333335
Confusion matrix :
[[117  15  24]
 [ 55  23  18]
 [112  63  53]]
Accuracy low :
0.5708333333333333
Accuracy medium :
0.6854166666666667
Accuracy high :
0.5479166666666667
Average accuracy :
0.6013888888888889
Classification report :
              precision    recall  f1-score   support

           0       0.41      0.75      0.53       156
           1       0.23      0.24      0.23        96
           2       0.56      0.23      0.33       228

    accuracy                           0.40       480
   macro avg       0.40      0.41      0.36       480
weighted avg       0.44      0.40      0.38       480

Fold6 - Test loss: 16.457
Fold6 - Test accuracy: 40.21%

Time 59.16 min
Fold7 - Train loss: 1176.178376197815
Accuracy :
0.3416666666666667
Confusion matrix :
[[ 99  36  21]
 [ 60  16  20]
 [124  55  49]]
Accuracy low :
0.4979166666666667
Accuracy medium :
0.64375
Accuracy high :
0.5416666666666666
Average accuracy :
0.561111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.35      0.63      0.45       156
           1       0.15      0.17      0.16        96
           2       0.54      0.21      0.31       228

    accuracy                           0.34       480
   macro avg       0.35      0.34      0.31       480
weighted avg       0.40      0.34      0.32       480

Fold7 - Test loss: 16.475
Fold7 - Test accuracy: 34.17%

Time 60.84 min
Fold8 - Train loss: 1323.1970853805542
Accuracy :
0.41875
Confusion matrix :
[[71 42 43]
 [30 40 26]
 [55 83 90]]
Accuracy low :
0.6458333333333334
Accuracy medium :
0.6229166666666667
Accuracy high :
0.56875
Average accuracy :
0.6124999999999999
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.46      0.46       156
           1       0.24      0.42      0.31        96
           2       0.57      0.39      0.47       228

    accuracy                           0.42       480
   macro avg       0.42      0.42      0.41       480
weighted avg       0.47      0.42      0.43       480

Fold8 - Test loss: 16.399
Fold8 - Test accuracy: 41.88%

Time 62.55 min
Fold9 - Train loss: 1470.1190954446793
Accuracy :
0.40625
Confusion matrix :
[[ 53  48  55]
 [ 38  29  29]
 [ 44  71 113]]
Accuracy low :
0.6145833333333334
Accuracy medium :
0.6125
Accuracy high :
0.5854166666666667
Average accuracy :
0.6041666666666666
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.34      0.36       156
           1       0.20      0.30      0.24        96
           2       0.57      0.50      0.53       228

    accuracy                           0.41       480
   macro avg       0.39      0.38      0.38       480
weighted avg       0.44      0.41      0.42       480

Fold9 - Test loss: 16.445
Fold9 - Test accuracy: 40.62%

EPOCH 3
Time 64.19 min
Fold0 - Train loss: 146.7116551399231
Accuracy :
0.38958333333333334
Confusion matrix :
[[59 59 37]
 [31 41 25]
 [73 68 87]]
Accuracy low :
0.5833333333333334
Accuracy medium :
0.61875
Accuracy high :
0.5770833333333333
Average accuracy :
0.5930555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.36      0.38      0.37       155
           1       0.24      0.42      0.31        97
           2       0.58      0.38      0.46       228

    accuracy                           0.39       480
   macro avg       0.40      0.39      0.38       480
weighted avg       0.44      0.39      0.40       480

Fold0 - Test loss: 16.416
Fold0 - Test accuracy: 38.96%

Time 65.88 min
Fold1 - Train loss: 293.4583103656769
Accuracy :
0.35625
Confusion matrix :
[[39 63 53]
 [24 42 31]
 [49 89 90]]
Accuracy low :
0.60625
Accuracy medium :
0.56875
Accuracy high :
0.5375
Average accuracy :
0.5708333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.35      0.25      0.29       155
           1       0.22      0.43      0.29        97
           2       0.52      0.39      0.45       228

    accuracy                           0.36       480
   macro avg       0.36      0.36      0.34       480
weighted avg       0.40      0.36      0.37       480

Fold1 - Test loss: 16.452
Fold1 - Test accuracy: 35.62%

Time 67.65 min
Fold2 - Train loss: 440.37219989299774
Accuracy :
0.37083333333333335
Confusion matrix :
[[ 56  49  50]
 [ 28  19  50]
 [ 69  56 103]]
Accuracy low :
0.5916666666666667
Accuracy medium :
0.61875
Accuracy high :
0.53125
Average accuracy :
0.5805555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.37      0.36      0.36       155
           1       0.15      0.20      0.17        97
           2       0.51      0.45      0.48       228

    accuracy                           0.37       480
   macro avg       0.34      0.34      0.34       480
weighted avg       0.39      0.37      0.38       480

Fold2 - Test loss: 16.526
Fold2 - Test accuracy: 37.08%

Time 69.35 min
Fold3 - Train loss: 587.4119155406952
Accuracy :
0.4479166666666667
Confusion matrix :
[[ 78  34  43]
 [ 30  37  29]
 [ 56  73 100]]
Accuracy low :
0.6604166666666667
Accuracy medium :
0.6541666666666667
Accuracy high :
0.58125
Average accuracy :
0.6319444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.50      0.49       155
           1       0.26      0.39      0.31        96
           2       0.58      0.44      0.50       229

    accuracy                           0.45       480
   macro avg       0.44      0.44      0.43       480
weighted avg       0.48      0.45      0.46       480

Fold3 - Test loss: 16.404
Fold3 - Test accuracy: 44.79%

Time 71.36 min
Fold4 - Train loss: 734.2709301710129
Accuracy :
0.42291666666666666
Confusion matrix :
[[ 27  43  85]
 [  8  30  58]
 [ 22  61 146]]
Accuracy low :
0.6708333333333333
Accuracy medium :
0.6458333333333334
Accuracy high :
0.5291666666666667
Average accuracy :
0.6152777777777777
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.17      0.25       155
           1       0.22      0.31      0.26        96
           2       0.51      0.64      0.56       229

    accuracy                           0.42       480
   macro avg       0.40      0.37      0.36       480
weighted avg       0.44      0.42      0.40       480

Fold4 - Test loss: 16.399
Fold4 - Test accuracy: 42.29%

Time 73.06 min
Fold5 - Train loss: 881.0960977077484
Accuracy :
0.3770833333333333
Confusion matrix :
[[ 22  42  91]
 [ 26  26  44]
 [ 47  49 133]]
Accuracy low :
0.5708333333333333
Accuracy medium :
0.6645833333333333
Accuracy high :
0.51875
Average accuracy :
0.5847222222222223
Classification report :
              precision    recall  f1-score   support

           0       0.23      0.14      0.18       155
           1       0.22      0.27      0.24        96
           2       0.50      0.58      0.54       229

    accuracy                           0.38       480
   macro avg       0.32      0.33      0.32       480
weighted avg       0.36      0.38      0.36       480

Fold5 - Test loss: 16.361
Fold5 - Test accuracy: 37.71%

Time 74.72 min
Fold6 - Train loss: 1028.0372326374054
Accuracy :
0.4708333333333333
Confusion matrix :
[[109  17  30]
 [ 46  16  34]
 [ 84  43 101]]
Accuracy low :
0.63125
Accuracy medium :
0.7083333333333334
Accuracy high :
0.6020833333333333
Average accuracy :
0.6472222222222223
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.70      0.55       156
           1       0.21      0.17      0.19        96
           2       0.61      0.44      0.51       228

    accuracy                           0.47       480
   macro avg       0.43      0.44      0.42       480
weighted avg       0.48      0.47      0.46       480

Fold6 - Test loss: 16.443
Fold6 - Test accuracy: 47.08%
saved model runs\semrel_model/semrel_model_best

Time 78.12 min
Fold7 - Train loss: 1174.9518834352493
Accuracy :
0.32916666666666666
Confusion matrix :
[[ 86  49  21]
 [ 53  23  20]
 [108  71  49]]
Accuracy low :
0.51875
Accuracy medium :
0.5979166666666667
Accuracy high :
0.5416666666666666
Average accuracy :
0.5527777777777777
Classification report :
              precision    recall  f1-score   support

           0       0.35      0.55      0.43       156
           1       0.16      0.24      0.19        96
           2       0.54      0.21      0.31       228

    accuracy                           0.33       480
   macro avg       0.35      0.34      0.31       480
weighted avg       0.40      0.33      0.32       480

Fold7 - Test loss: 16.461
Fold7 - Test accuracy: 32.92%

Time 79.88 min
Fold8 - Train loss: 1322.0175482034683
Accuracy :
0.36875
Confusion matrix :
[[ 72  57  27]
 [ 31  44  21]
 [ 56 111  61]]
Accuracy low :
0.64375
Accuracy medium :
0.5416666666666666
Accuracy high :
0.5520833333333334
Average accuracy :
0.5791666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.45      0.46      0.46       156
           1       0.21      0.46      0.29        96
           2       0.56      0.27      0.36       228

    accuracy                           0.37       480
   macro avg       0.41      0.40      0.37       480
weighted avg       0.45      0.37      0.38       480

Fold8 - Test loss: 16.431
Fold8 - Test accuracy: 36.88%

Time 81.65 min
Fold9 - Train loss: 1468.774689912796
Accuracy :
0.3645833333333333
Confusion matrix :
[[107  29  20]
 [ 60  25  11]
 [104  81  43]]
Accuracy low :
0.55625
Accuracy medium :
0.6229166666666667
Accuracy high :
0.55
Average accuracy :
0.576388888888889
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.69      0.50       156
           1       0.19      0.26      0.22        96
           2       0.58      0.19      0.28       228

    accuracy                           0.36       480
   macro avg       0.39      0.38      0.33       480
weighted avg       0.44      0.36      0.34       480

Fold9 - Test loss: 16.371
Fold9 - Test accuracy: 36.46%

EPOCH 4
Time 83.30 min
Fold0 - Train loss: 146.860253572464
Accuracy :
0.37916666666666665
Confusion matrix :
[[ 46  73  36]
 [ 17  55  25]
 [ 46 101  81]]
Accuracy low :
0.6416666666666667
Accuracy medium :
0.55
Accuracy high :
0.5666666666666667
Average accuracy :
0.5861111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.42      0.30      0.35       155
           1       0.24      0.57      0.34        97
           2       0.57      0.36      0.44       228

    accuracy                           0.38       480
   macro avg       0.41      0.41      0.37       480
weighted avg       0.46      0.38      0.39       480

Fold0 - Test loss: 16.453
Fold0 - Test accuracy: 37.92%

Time 85.02 min
Fold1 - Train loss: 293.7428797483444
Accuracy :
0.41458333333333336
Confusion matrix :
[[56 61 38]
 [21 46 30]
 [36 95 97]]
Accuracy low :
0.675
Accuracy medium :
0.56875
Accuracy high :
0.5854166666666667
Average accuracy :
0.6097222222222222
Classification report :
              precision    recall  f1-score   support

           0       0.50      0.36      0.42       155
           1       0.23      0.47      0.31        97
           2       0.59      0.43      0.49       228

    accuracy                           0.41       480
   macro avg       0.44      0.42      0.41       480
weighted avg       0.49      0.41      0.43       480

Fold1 - Test loss: 16.453
Fold1 - Test accuracy: 41.46%

Time 86.74 min
Fold2 - Train loss: 440.5748997926712
Accuracy :
0.38125
Confusion matrix :
[[ 32  45  78]
 [ 23  30  44]
 [ 59  48 121]]
Accuracy low :
0.5729166666666666
Accuracy medium :
0.6666666666666666
Accuracy high :
0.5229166666666667
Average accuracy :
0.5875
Classification report :
              precision    recall  f1-score   support

           0       0.28      0.21      0.24       155
           1       0.24      0.31      0.27        97
           2       0.50      0.53      0.51       228

    accuracy                           0.38       480
   macro avg       0.34      0.35      0.34       480
weighted avg       0.38      0.38      0.38       480

Fold2 - Test loss: 16.429
Fold2 - Test accuracy: 38.12%

Time 88.44 min
Fold3 - Train loss: 587.610326051712
Accuracy :
0.425
Confusion matrix :
[[ 46  46  63]
 [ 18  35  43]
 [ 32  74 123]]
Accuracy low :
0.66875
Accuracy medium :
0.6229166666666667
Accuracy high :
0.5583333333333333
Average accuracy :
0.6166666666666666
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.30      0.37       155
           1       0.23      0.36      0.28        96
           2       0.54      0.54      0.54       229

    accuracy                           0.42       480
   macro avg       0.41      0.40      0.39       480
weighted avg       0.46      0.42      0.43       480

Fold3 - Test loss: 16.386
Fold3 - Test accuracy: 42.50%

Time 90.17 min
Fold4 - Train loss: 734.6091966629028
Accuracy :
0.40625
Confusion matrix :
[[ 30  37  88]
 [ 16  27  53]
 [ 30  61 138]]
Accuracy low :
0.64375
Accuracy medium :
0.6520833333333333
Accuracy high :
0.5166666666666667
Average accuracy :
0.6041666666666666
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.19      0.26       155
           1       0.22      0.28      0.24        96
           2       0.49      0.60      0.54       229

    accuracy                           0.41       480
   macro avg       0.37      0.36      0.35       480
weighted avg       0.41      0.41      0.39       480

Fold4 - Test loss: 16.336
Fold4 - Test accuracy: 40.62%

Time 91.88 min
Fold5 - Train loss: 881.438504576683
Accuracy :
0.46041666666666664
Confusion matrix :
[[ 29  41  85]
 [  9  26  61]
 [ 25  38 166]]
Accuracy low :
0.6666666666666666
Accuracy medium :
0.6895833333333333
Accuracy high :
0.5645833333333333
Average accuracy :
0.6402777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.19      0.27       155
           1       0.25      0.27      0.26        96
           2       0.53      0.72      0.61       229

    accuracy                           0.46       480
   macro avg       0.41      0.39      0.38       480
weighted avg       0.45      0.46      0.43       480

Fold5 - Test loss: 16.331
Fold5 - Test accuracy: 46.04%

Time 93.54 min
Fold6 - Train loss: 1028.351316690445
Accuracy :
0.44166666666666665
Confusion matrix :
[[110  17  29]
 [ 49  12  35]
 [ 92  46  90]]
Accuracy low :
0.6104166666666667
Accuracy medium :
0.69375
Accuracy high :
0.5791666666666667
Average accuracy :
0.6277777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.71      0.54       156
           1       0.16      0.12      0.14        96
           2       0.58      0.39      0.47       228

    accuracy                           0.44       480
   macro avg       0.39      0.41      0.38       480
weighted avg       0.45      0.44      0.43       480

Fold6 - Test loss: 16.462
Fold6 - Test accuracy: 44.17%

Time 95.24 min
Fold7 - Train loss: 1175.1808185577393
Accuracy :
0.44166666666666665
Confusion matrix :
[[ 72  25  59]
 [ 36  22  38]
 [ 74  36 118]]
Accuracy low :
0.5958333333333333
Accuracy medium :
0.71875
Accuracy high :
0.56875
Average accuracy :
0.6277777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.40      0.46      0.43       156
           1       0.27      0.23      0.25        96
           2       0.55      0.52      0.53       228

    accuracy                           0.44       480
   macro avg       0.40      0.40      0.40       480
weighted avg       0.44      0.44      0.44       480

Fold7 - Test loss: 16.451
Fold7 - Test accuracy: 44.17%

Time 96.91 min
Fold8 - Train loss: 1322.0334284305573
Accuracy :
0.4125
Confusion matrix :
[[66 42 48]
 [23 44 29]
 [49 91 88]]
Accuracy low :
0.6625
Accuracy medium :
0.6145833333333334
Accuracy high :
0.5479166666666667
Average accuracy :
0.6083333333333334
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.42      0.45       156
           1       0.25      0.46      0.32        96
           2       0.53      0.39      0.45       228

    accuracy                           0.41       480
   macro avg       0.42      0.42      0.41       480
weighted avg       0.46      0.41      0.42       480

Fold8 - Test loss: 16.412
Fold8 - Test accuracy: 41.25%

Time 98.63 min
Fold9 - Train loss: 1468.537308216095
Accuracy :
0.41458333333333336
Confusion matrix :
[[ 58  42  56]
 [ 31  30  35]
 [ 44  73 111]]
Accuracy low :
0.6395833333333333
Accuracy medium :
0.6229166666666667
Accuracy high :
0.5666666666666667
Average accuracy :
0.6097222222222222
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.37      0.40       156
           1       0.21      0.31      0.25        96
           2       0.55      0.49      0.52       228

    accuracy                           0.41       480
   macro avg       0.40      0.39      0.39       480
weighted avg       0.44      0.41      0.43       480

Fold9 - Test loss: 16.473
Fold9 - Test accuracy: 41.46%

EPOCH 5
Time 100.29 min
Fold0 - Train loss: 146.85413074493408
Accuracy :
0.3854166666666667
Confusion matrix :
[[48 68 39]
 [27 44 26]
 [60 75 93]]
Accuracy low :
0.5958333333333333
Accuracy medium :
0.5916666666666667
Accuracy high :
0.5833333333333334
Average accuracy :
0.5902777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.36      0.31      0.33       155
           1       0.24      0.45      0.31        97
           2       0.59      0.41      0.48       228

    accuracy                           0.39       480
   macro avg       0.39      0.39      0.37       480
weighted avg       0.44      0.39      0.40       480

Fold0 - Test loss: 16.401
Fold0 - Test accuracy: 38.54%

Time 101.97 min
Fold1 - Train loss: 293.6243883371353
Accuracy :
0.3854166666666667
Confusion matrix :
[[ 46  65  44]
 [ 20  47  30]
 [ 34 102  92]]
Accuracy low :
0.6604166666666667
Accuracy medium :
0.5479166666666667
Accuracy high :
0.5625
Average accuracy :
0.5902777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.30      0.36       155
           1       0.22      0.48      0.30        97
           2       0.55      0.40      0.47       228

    accuracy                           0.39       480
   macro avg       0.41      0.39      0.38       480
weighted avg       0.46      0.39      0.40       480

Fold1 - Test loss: 16.444
Fold1 - Test accuracy: 38.54%

Time 103.70 min
Fold2 - Train loss: 440.5728840827942
Accuracy :
0.35208333333333336
Confusion matrix :
[[43 62 50]
 [16 35 46]
 [46 91 91]]
Accuracy low :
0.6375
Accuracy medium :
0.5520833333333334
Accuracy high :
0.5145833333333333
Average accuracy :
0.5680555555555555
Classification report :
              precision    recall  f1-score   support

           0       0.41      0.28      0.33       155
           1       0.19      0.36      0.25        97
           2       0.49      0.40      0.44       228

    accuracy                           0.35       480
   macro avg       0.36      0.35      0.34       480
weighted avg       0.40      0.35      0.36       480

Fold2 - Test loss: 16.525
Fold2 - Test accuracy: 35.21%

Time 105.41 min
Fold3 - Train loss: 587.463103055954
Accuracy :
0.45416666666666666
Confusion matrix :
[[ 69  39  47]
 [ 22  49  25]
 [ 34  95 100]]
Accuracy low :
0.7041666666666667
Accuracy medium :
0.6229166666666667
Accuracy high :
0.58125
Average accuracy :
0.6361111111111112
Classification report :
              precision    recall  f1-score   support

           0       0.55      0.45      0.49       155
           1       0.27      0.51      0.35        96
           2       0.58      0.44      0.50       229

    accuracy                           0.45       480
   macro avg       0.47      0.46      0.45       480
weighted avg       0.51      0.45      0.47       480

Fold3 - Test loss: 16.399
Fold3 - Test accuracy: 45.42%

Time 107.14 min
Fold4 - Train loss: 734.3933418989182
Accuracy :
0.375
Confusion matrix :
[[ 23  46  86]
 [ 12  28  56]
 [ 26  74 129]]
Accuracy low :
0.6458333333333334
Accuracy medium :
0.6083333333333333
Accuracy high :
0.49583333333333335
Average accuracy :
0.5833333333333334
Classification report :
              precision    recall  f1-score   support

           0       0.38      0.15      0.21       155
           1       0.19      0.29      0.23        96
           2       0.48      0.56      0.52       229

    accuracy                           0.38       480
   macro avg       0.35      0.33      0.32       480
weighted avg       0.39      0.38      0.36       480

Fold4 - Test loss: 16.400
Fold4 - Test accuracy: 37.50%

Time 108.84 min
Fold5 - Train loss: 881.3164921998978
Accuracy :
0.47291666666666665
Confusion matrix :
[[ 89  31  35]
 [ 33  28  35]
 [ 80  39 110]]
Accuracy low :
0.6270833333333333
Accuracy medium :
0.7125
Accuracy high :
0.60625
Average accuracy :
0.6486111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.57      0.50       155
           1       0.29      0.29      0.29        96
           2       0.61      0.48      0.54       229

    accuracy                           0.47       480
   macro avg       0.45      0.45      0.44       480
weighted avg       0.49      0.47      0.48       480

Fold5 - Test loss: 16.374
Fold5 - Test accuracy: 47.29%
saved model runs\semrel_model/semrel_model_best

Time 111.95 min
Fold6 - Train loss: 1028.9928154945374
Accuracy :
0.475
Confusion matrix :
[[109  17  30]
 [ 44  15  37]
 [ 80  44 104]]
Accuracy low :
0.64375
Accuracy medium :
0.7041666666666667
Accuracy high :
0.6020833333333333
Average accuracy :
0.65
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.70      0.56       156
           1       0.20      0.16      0.17        96
           2       0.61      0.46      0.52       228

    accuracy                           0.48       480
   macro avg       0.42      0.44      0.42       480
weighted avg       0.48      0.47      0.46       480

Fold6 - Test loss: 16.458
Fold6 - Test accuracy: 47.50%
saved model runs\semrel_model/semrel_model_best

Time 114.96 min
Fold7 - Train loss: 1176.5410894155502
Accuracy :
0.4041666666666667
Confusion matrix :
[[76 36 44]
 [38 32 26]
 [79 63 86]]
Accuracy low :
0.5895833333333333
Accuracy medium :
0.6604166666666667
Accuracy high :
0.5583333333333333
Average accuracy :
0.6027777777777777
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.49      0.44       156
           1       0.24      0.33      0.28        96
           2       0.55      0.38      0.45       228

    accuracy                           0.40       480
   macro avg       0.40      0.40      0.39       480
weighted avg       0.44      0.40      0.41       480

Fold7 - Test loss: 16.389
Fold7 - Test accuracy: 40.42%

Time 116.84 min
Fold8 - Train loss: 1324.188115477562
Accuracy :
0.4875
Confusion matrix :
[[ 65  24  67]
 [ 20  29  47]
 [ 46  42 140]]
Accuracy low :
0.6729166666666667
Accuracy medium :
0.7229166666666667
Accuracy high :
0.5791666666666667
Average accuracy :
0.6583333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.50      0.42      0.45       156
           1       0.31      0.30      0.30        96
           2       0.55      0.61      0.58       228

    accuracy                           0.49       480
   macro avg       0.45      0.44      0.45       480
weighted avg       0.48      0.49      0.48       480

Fold8 - Test loss: 16.414
Fold8 - Test accuracy: 48.75%
saved model runs\semrel_model/semrel_model_best

Time 120.04 min
Fold9 - Train loss: 1471.6633231639862
Accuracy :
0.41875
Confusion matrix :
[[91 33 32]
 [45 31 20]
 [72 77 79]]
Accuracy low :
0.6208333333333333
Accuracy medium :
0.6354166666666666
Accuracy high :
0.58125
Average accuracy :
0.6125
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.58      0.50       156
           1       0.22      0.32      0.26        96
           2       0.60      0.35      0.44       228

    accuracy                           0.42       480
   macro avg       0.42      0.42      0.40       480
weighted avg       0.47      0.42      0.42       480

Fold9 - Test loss: 16.481
Fold9 - Test accuracy: 41.88%

EPOCH 6
Time 121.70 min
Fold0 - Train loss: 147.56477618217468
Accuracy :
0.45208333333333334
Confusion matrix :
[[ 30  28  97]
 [ 14  29  54]
 [ 24  46 158]]
Accuracy low :
0.6604166666666667
Accuracy medium :
0.7041666666666667
Accuracy high :
0.5395833333333333
Average accuracy :
0.6347222222222223
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.19      0.27       155
           1       0.28      0.30      0.29        97
           2       0.51      0.69      0.59       228

    accuracy                           0.45       480
   macro avg       0.41      0.40      0.38       480
weighted avg       0.44      0.45      0.43       480

Fold0 - Test loss: 16.374
Fold0 - Test accuracy: 45.21%

Time 123.43 min
Fold1 - Train loss: 295.13644778728485
Accuracy :
0.425
Confusion matrix :
[[ 39  66  50]
 [ 15  44  38]
 [ 31  76 121]]
Accuracy low :
0.6625
Accuracy medium :
0.59375
Accuracy high :
0.59375
Average accuracy :
0.6166666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.25      0.32       155
           1       0.24      0.45      0.31        97
           2       0.58      0.53      0.55       228

    accuracy                           0.42       480
   macro avg       0.42      0.41      0.40       480
weighted avg       0.47      0.42      0.43       480

Fold1 - Test loss: 16.405
Fold1 - Test accuracy: 42.50%

Time 125.16 min
Fold2 - Train loss: 442.54563415050507
Accuracy :
0.37083333333333335
Confusion matrix :
[[ 28  74  53]
 [ 14  48  35]
 [ 50  76 102]]
Accuracy low :
0.6020833333333333
Accuracy medium :
0.5854166666666667
Accuracy high :
0.5541666666666667
Average accuracy :
0.5805555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.30      0.18      0.23       155
           1       0.24      0.49      0.33        97
           2       0.54      0.45      0.49       228

    accuracy                           0.37       480
   macro avg       0.36      0.37      0.35       480
weighted avg       0.40      0.37      0.37       480

Fold2 - Test loss: 16.427
Fold2 - Test accuracy: 37.08%

Time 126.85 min
Fold3 - Train loss: 590.0881996154785
Accuracy :
0.45208333333333334
Confusion matrix :
[[ 67  42  46]
 [ 19  46  31]
 [ 30  95 104]]
Accuracy low :
0.7145833333333333
Accuracy medium :
0.6104166666666667
Accuracy high :
0.5791666666666667
Average accuracy :
0.6347222222222223
Classification report :
              precision    recall  f1-score   support

           0       0.58      0.43      0.49       155
           1       0.25      0.48      0.33        96
           2       0.57      0.45      0.51       229

    accuracy                           0.45       480
   macro avg       0.47      0.46      0.44       480
weighted avg       0.51      0.45      0.47       480

Fold3 - Test loss: 16.389
Fold3 - Test accuracy: 45.21%

Time 128.60 min
Fold4 - Train loss: 737.7019966840744
Accuracy :
0.46041666666666664
Confusion matrix :
[[125  12  18]
 [ 55  22  19]
 [ 79  76  74]]
Accuracy low :
0.6583333333333333
Accuracy medium :
0.6625
Accuracy high :
0.6
Average accuracy :
0.6402777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.81      0.60       155
           1       0.20      0.23      0.21        96
           2       0.67      0.32      0.44       229

    accuracy                           0.46       480
   macro avg       0.45      0.45      0.42       480
weighted avg       0.51      0.46      0.45       480

Fold4 - Test loss: 16.469
Fold4 - Test accuracy: 46.04%

Time 130.31 min
Fold5 - Train loss: 884.9766609668732
Accuracy :
0.4666666666666667
Confusion matrix :
[[ 69  35  51]
 [ 24  27  45]
 [ 57  44 128]]
Accuracy low :
0.6520833333333333
Accuracy medium :
0.6916666666666667
Accuracy high :
0.5895833333333333
Average accuracy :
0.6444444444444445
Classification report :
              precision    recall  f1-score   support

           0       0.46      0.45      0.45       155
           1       0.25      0.28      0.27        96
           2       0.57      0.56      0.57       229

    accuracy                           0.47       480
   macro avg       0.43      0.43      0.43       480
weighted avg       0.47      0.47      0.47       480

Fold5 - Test loss: 16.414
Fold5 - Test accuracy: 46.67%

Time 131.97 min
Fold6 - Train loss: 1032.5127573013306
Accuracy :
0.45625
Confusion matrix :
[[108  18  30]
 [ 44  15  37]
 [ 80  52  96]]
Accuracy low :
0.6416666666666667
Accuracy medium :
0.6854166666666667
Accuracy high :
0.5854166666666667
Average accuracy :
0.6375000000000001
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.69      0.56       156
           1       0.18      0.16      0.17        96
           2       0.59      0.42      0.49       228

    accuracy                           0.46       480
   macro avg       0.41      0.42      0.40       480
weighted avg       0.47      0.46      0.45       480

Fold6 - Test loss: 16.476
Fold6 - Test accuracy: 45.62%

Time 133.65 min
Fold7 - Train loss: 1179.8559604883194
Accuracy :
0.37083333333333335
Confusion matrix :
[[82 44 30]
 [39 32 25]
 [87 77 64]]
Accuracy low :
0.5833333333333334
Accuracy medium :
0.6145833333333334
Accuracy high :
0.54375
Average accuracy :
0.5805555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.53      0.45       156
           1       0.21      0.33      0.26        96
           2       0.54      0.28      0.37       228

    accuracy                           0.37       480
   macro avg       0.38      0.38      0.36       480
weighted avg       0.43      0.37      0.37       480

Fold7 - Test loss: 16.437
Fold7 - Test accuracy: 37.08%

Time 135.30 min
Fold8 - Train loss: 1327.3051890134811
Accuracy :
0.48125
Confusion matrix :
[[ 65  31  60]
 [ 20  36  40]
 [ 46  52 130]]
Accuracy low :
0.6729166666666667
Accuracy medium :
0.7020833333333333
Accuracy high :
0.5875
Average accuracy :
0.6541666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.50      0.42      0.45       156
           1       0.30      0.38      0.33        96
           2       0.57      0.57      0.57       228

    accuracy                           0.48       480
   macro avg       0.45      0.45      0.45       480
weighted avg       0.49      0.48      0.48       480

Fold8 - Test loss: 16.377
Fold8 - Test accuracy: 48.12%

Time 137.01 min
Fold9 - Train loss: 1474.7461185455322
Accuracy :
0.4166666666666667
Confusion matrix :
[[89 32 35]
 [44 30 22]
 [70 77 81]]
Accuracy low :
0.6229166666666667
Accuracy medium :
0.6354166666666666
Accuracy high :
0.575
Average accuracy :
0.611111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.44      0.57      0.50       156
           1       0.22      0.31      0.26        96
           2       0.59      0.36      0.44       228

    accuracy                           0.42       480
   macro avg       0.41      0.41      0.40       480
weighted avg       0.46      0.42      0.42       480

Fold9 - Test loss: 16.444
Fold9 - Test accuracy: 41.67%

EPOCH 7
Time 138.68 min
Fold0 - Train loss: 147.5314403772354
Accuracy :
0.4270833333333333
Confusion matrix :
[[ 33  43  79]
 [ 12  40  45]
 [ 28  68 132]]
Accuracy low :
0.6625
Accuracy medium :
0.65
Accuracy high :
0.5416666666666666
Average accuracy :
0.6180555555555555
Classification report :
              precision    recall  f1-score   support

           0       0.45      0.21      0.29       155
           1       0.26      0.41      0.32        97
           2       0.52      0.58      0.55       228

    accuracy                           0.43       480
   macro avg       0.41      0.40      0.39       480
weighted avg       0.44      0.43      0.42       480

Fold0 - Test loss: 16.361
Fold0 - Test accuracy: 42.71%

Time 140.40 min
Fold1 - Train loss: 294.9608225822449
Accuracy :
0.4395833333333333
Confusion matrix :
[[ 30  53  72]
 [ 16  29  52]
 [ 23  53 152]]
Accuracy low :
0.6583333333333333
Accuracy medium :
0.6375
Accuracy high :
0.5833333333333334
Average accuracy :
0.626388888888889
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.19      0.27       155
           1       0.21      0.30      0.25        97
           2       0.55      0.67      0.60       228

    accuracy                           0.44       480
   macro avg       0.40      0.39      0.37       480
weighted avg       0.45      0.44      0.42       480

Fold1 - Test loss: 16.391
Fold1 - Test accuracy: 43.96%

Time 142.11 min
Fold2 - Train loss: 442.4213675260544
Accuracy :
0.36875
Confusion matrix :
[[ 25  70  60]
 [ 13  43  41]
 [ 41  78 109]]
Accuracy low :
0.6166666666666667
Accuracy medium :
0.5791666666666667
Accuracy high :
0.5416666666666666
Average accuracy :
0.5791666666666666
Classification report :
              precision    recall  f1-score   support

           0       0.32      0.16      0.21       155
           1       0.23      0.44      0.30        97
           2       0.52      0.48      0.50       228

    accuracy                           0.37       480
   macro avg       0.35      0.36      0.34       480
weighted avg       0.39      0.37      0.37       480

Fold2 - Test loss: 16.422
Fold2 - Test accuracy: 36.88%

Time 143.78 min
Fold3 - Train loss: 589.8755241632462
Accuracy :
0.49583333333333335
Confusion matrix :
[[ 62  42  51]
 [ 15  48  33]
 [ 21  80 128]]
Accuracy low :
0.73125
Accuracy medium :
0.6458333333333334
Accuracy high :
0.6145833333333334
Average accuracy :
0.6638888888888889
Classification report :
              precision    recall  f1-score   support

           0       0.63      0.40      0.49       155
           1       0.28      0.50      0.36        96
           2       0.60      0.56      0.58       229

    accuracy                           0.50       480
   macro avg       0.51      0.49      0.48       480
weighted avg       0.55      0.50      0.51       480

Fold3 - Test loss: 16.396
Fold3 - Test accuracy: 49.58%
saved model runs\semrel_model/semrel_model_best

Time 147.10 min
Fold4 - Train loss: 737.430296421051
Accuracy :
0.45416666666666666
Confusion matrix :
[[ 52  46  57]
 [ 19  25  52]
 [ 20  68 141]]
Accuracy low :
0.7041666666666667
Accuracy medium :
0.6145833333333334
Accuracy high :
0.5895833333333333
Average accuracy :
0.6361111111111112
Classification report :
              precision    recall  f1-score   support

           0       0.57      0.34      0.42       155
           1       0.18      0.26      0.21        96
           2       0.56      0.62      0.59       229

    accuracy                           0.45       480
   macro avg       0.44      0.40      0.41       480
weighted avg       0.49      0.45      0.46       480

Fold4 - Test loss: 16.428
Fold4 - Test accuracy: 45.42%

Time 148.80 min
Fold5 - Train loss: 884.6679784059525
Accuracy :
0.50625
Confusion matrix :
[[ 65  36  54]
 [ 19  31  46]
 [ 41  41 147]]
Accuracy low :
0.6875
Accuracy medium :
0.7041666666666667
Accuracy high :
0.6208333333333333
Average accuracy :
0.6708333333333334
Classification report :
              precision    recall  f1-score   support

           0       0.52      0.42      0.46       155
           1       0.29      0.32      0.30        96
           2       0.60      0.64      0.62       229

    accuracy                           0.51       480
   macro avg       0.47      0.46      0.46       480
weighted avg       0.51      0.51      0.51       480

Fold5 - Test loss: 16.361
Fold5 - Test accuracy: 50.62%
saved model runs\semrel_model/semrel_model_best

Time 151.66 min
Fold6 - Train loss: 1032.0625183582306
Accuracy :
0.4125
Confusion matrix :
[[108  24  24]
 [ 44  29  23]
 [ 80  87  61]]
Accuracy low :
0.6416666666666667
Accuracy medium :
0.6291666666666667
Accuracy high :
0.5541666666666667
Average accuracy :
0.6083333333333334
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.69      0.56       156
           1       0.21      0.30      0.25        96
           2       0.56      0.27      0.36       228

    accuracy                           0.41       480
   macro avg       0.41      0.42      0.39       480
weighted avg       0.46      0.41      0.40       480

Fold6 - Test loss: 16.481
Fold6 - Test accuracy: 41.25%

Time 153.35 min
Fold7 - Train loss: 1179.3680630922318
Accuracy :
0.34375
Confusion matrix :
[[82 42 32]
 [45 25 26]
 [90 80 58]]
Accuracy low :
0.5645833333333333
Accuracy medium :
0.5979166666666667
Accuracy high :
0.525
Average accuracy :
0.5625
Classification report :
              precision    recall  f1-score   support

           0       0.38      0.53      0.44       156
           1       0.17      0.26      0.21        96
           2       0.50      0.25      0.34       228

    accuracy                           0.34       480
   macro avg       0.35      0.35      0.33       480
weighted avg       0.39      0.34      0.34       480

Fold7 - Test loss: 16.444
Fold7 - Test accuracy: 34.38%

Time 155.27 min
Fold8 - Train loss: 1326.7746821641922
Accuracy :
0.475
Confusion matrix :
[[ 65  32  59]
 [ 20  36  40]
 [ 45  56 127]]
Accuracy low :
0.675
Accuracy medium :
0.6916666666666667
Accuracy high :
0.5833333333333334
Average accuracy :
0.65
Classification report :
              precision    recall  f1-score   support

           0       0.50      0.42      0.45       156
           1       0.29      0.38      0.33        96
           2       0.56      0.56      0.56       228

    accuracy                           0.48       480
   macro avg       0.45      0.45      0.45       480
weighted avg       0.49      0.47      0.48       480

Fold8 - Test loss: 16.377
Fold8 - Test accuracy: 47.50%

Time 157.29 min
Fold9 - Train loss: 1474.1682453155518
Accuracy :
0.37916666666666665
Confusion matrix :
[[93 33 30]
 [47 28 21]
 [75 92 61]]
Accuracy low :
0.6145833333333334
Accuracy medium :
0.5979166666666667
Accuracy high :
0.5458333333333333
Average accuracy :
0.5861111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.60      0.50       156
           1       0.18      0.29      0.22        96
           2       0.54      0.27      0.36       228

    accuracy                           0.38       480
   macro avg       0.39      0.39      0.36       480
weighted avg       0.44      0.38      0.38       480

Fold9 - Test loss: 16.422
Fold9 - Test accuracy: 37.92%

EPOCH 8
Time 159.23 min
Fold0 - Train loss: 147.57393956184387
Accuracy :
0.4125
Confusion matrix :
[[ 39  44  72]
 [ 17  35  45]
 [ 35  69 124]]
Accuracy low :
0.65
Accuracy medium :
0.6354166666666666
Accuracy high :
0.5395833333333333
Average accuracy :
0.6083333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.25      0.32       155
           1       0.24      0.36      0.29        97
           2       0.51      0.54      0.53       228

    accuracy                           0.41       480
   macro avg       0.39      0.39      0.38       480
weighted avg       0.43      0.41      0.41       480

Fold0 - Test loss: 16.415
Fold0 - Test accuracy: 41.25%

Time 161.02 min
Fold1 - Train loss: 294.9993416070938
Accuracy :
0.43125
Confusion matrix :
[[ 30  56  69]
 [ 16  32  49]
 [ 23  60 145]]
Accuracy low :
0.6583333333333333
Accuracy medium :
0.6229166666666667
Accuracy high :
0.58125
Average accuracy :
0.6208333333333333
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.19      0.27       155
           1       0.22      0.33      0.26        97
           2       0.55      0.64      0.59       228

    accuracy                           0.43       480
   macro avg       0.40      0.39      0.37       480
weighted avg       0.45      0.43      0.42       480

Fold1 - Test loss: 16.389
Fold1 - Test accuracy: 43.12%

Time 162.75 min
Fold2 - Train loss: 442.3356759548187
Accuracy :
0.36875
Confusion matrix :
[[ 21  75  59]
 [  8  47  42]
 [ 32  87 109]]
Accuracy low :
0.6375
Accuracy medium :
0.5583333333333333
Accuracy high :
0.5416666666666666
Average accuracy :
0.5791666666666666
Classification report :
              precision    recall  f1-score   support

           0       0.34      0.14      0.19       155
           1       0.22      0.48      0.31        97
           2       0.52      0.48      0.50       228

    accuracy                           0.37       480
   macro avg       0.36      0.37      0.33       480
weighted avg       0.40      0.37      0.36       480

Fold2 - Test loss: 16.420
Fold2 - Test accuracy: 36.88%

Time 164.45 min
Fold3 - Train loss: 589.7568384408951
Accuracy :
0.47291666666666665
Confusion matrix :
[[ 60  44  51]
 [ 15  47  34]
 [ 25  84 120]]
Accuracy low :
0.71875
Accuracy medium :
0.63125
Accuracy high :
0.5958333333333333
Average accuracy :
0.6486111111111111
Classification report :
              precision    recall  f1-score   support

           0       0.60      0.39      0.47       155
           1       0.27      0.49      0.35        96
           2       0.59      0.52      0.55       229

    accuracy                           0.47       480
   macro avg       0.48      0.47      0.46       480
weighted avg       0.53      0.47      0.49       480

Fold3 - Test loss: 16.398
Fold3 - Test accuracy: 47.29%

Time 166.19 min
Fold4 - Train loss: 737.1982493400574
Accuracy :
0.4666666666666667
Confusion matrix :
[[125  14  16]
 [ 54  26  16]
 [ 78  78  73]]
Accuracy low :
0.6625
Accuracy medium :
0.6625
Accuracy high :
0.6083333333333333
Average accuracy :
0.6444444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.49      0.81      0.61       155
           1       0.22      0.27      0.24        96
           2       0.70      0.32      0.44       229

    accuracy                           0.47       480
   macro avg       0.47      0.47      0.43       480
weighted avg       0.53      0.47      0.45       480

Fold4 - Test loss: 16.466
Fold4 - Test accuracy: 46.67%

Time 167.89 min
Fold5 - Train loss: 884.4556509256363
Accuracy :
0.46458333333333335
Confusion matrix :
[[ 59  39  57]
 [ 23  30  43]
 [ 42  53 134]]
Accuracy low :
0.6645833333333333
Accuracy medium :
0.6708333333333333
Accuracy high :
0.59375
Average accuracy :
0.6430555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.38      0.42       155
           1       0.25      0.31      0.28        96
           2       0.57      0.59      0.58       229

    accuracy                           0.46       480
   macro avg       0.43      0.43      0.43       480
weighted avg       0.48      0.46      0.47       480

Fold5 - Test loss: 16.355
Fold5 - Test accuracy: 46.46%

Time 169.57 min
Fold6 - Train loss: 1031.8486491441727
Accuracy :
0.45625
Confusion matrix :
[[108  23  25]
 [ 43  18  35]
 [ 80  55  93]]
Accuracy low :
0.64375
Accuracy medium :
0.675
Accuracy high :
0.59375
Average accuracy :
0.6375000000000001
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.69      0.56       156
           1       0.19      0.19      0.19        96
           2       0.61      0.41      0.49       228

    accuracy                           0.46       480
   macro avg       0.42      0.43      0.41       480
weighted avg       0.48      0.46      0.45       480

Fold6 - Test loss: 16.473
Fold6 - Test accuracy: 45.62%

Time 171.37 min
Fold7 - Train loss: 1179.2211402654648
Accuracy :
0.38958333333333334
Confusion matrix :
[[80 29 47]
 [43 25 28]
 [94 52 82]]
Accuracy low :
0.55625
Accuracy medium :
0.6833333333333333
Accuracy high :
0.5395833333333333
Average accuracy :
0.5930555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.37      0.51      0.43       156
           1       0.24      0.26      0.25        96
           2       0.52      0.36      0.43       228

    accuracy                           0.39       480
   macro avg       0.38      0.38      0.37       480
weighted avg       0.42      0.39      0.39       480

Fold7 - Test loss: 16.432
Fold7 - Test accuracy: 38.96%

Time 173.10 min
Fold8 - Train loss: 1326.543938279152
Accuracy :
0.48333333333333334
Confusion matrix :
[[ 65  30  61]
 [ 19  37  40]
 [ 44  54 130]]
Accuracy low :
0.6791666666666667
Accuracy medium :
0.7020833333333333
Accuracy high :
0.5854166666666667
Average accuracy :
0.6555555555555556
Classification report :
              precision    recall  f1-score   support

           0       0.51      0.42      0.46       156
           1       0.31      0.39      0.34        96
           2       0.56      0.57      0.57       228

    accuracy                           0.48       480
   macro avg       0.46      0.46      0.46       480
weighted avg       0.49      0.48      0.49       480

Fold8 - Test loss: 16.386
Fold8 - Test accuracy: 48.33%

Time 174.86 min
Fold9 - Train loss: 1473.9064257144928
Accuracy :
0.4083333333333333
Confusion matrix :
[[97 26 33]
 [52 28 16]
 [76 81 71]]
Accuracy low :
0.6104166666666667
Accuracy medium :
0.6354166666666666
Accuracy high :
0.5708333333333333
Average accuracy :
0.6055555555555555
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.62      0.51       156
           1       0.21      0.29      0.24        96
           2       0.59      0.31      0.41       228

    accuracy                           0.41       480
   macro avg       0.41      0.41      0.39       480
weighted avg       0.46      0.41      0.41       480

Fold9 - Test loss: 16.427
Fold9 - Test accuracy: 40.83%

EPOCH 9
Time 176.66 min
Fold0 - Train loss: 147.53278172016144
Accuracy :
0.41458333333333336
Confusion matrix :
[[ 34  49  72]
 [ 13  43  41]
 [ 32  74 122]]
Accuracy low :
0.6541666666666667
Accuracy medium :
0.63125
Accuracy high :
0.54375
Average accuracy :
0.6097222222222222
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.22      0.29       155
           1       0.26      0.44      0.33        97
           2       0.52      0.54      0.53       228

    accuracy                           0.41       480
   macro avg       0.40      0.40      0.38       480
weighted avg       0.44      0.41      0.41       480

Fold0 - Test loss: 16.380
Fold0 - Test accuracy: 41.46%

Time 178.33 min
Fold1 - Train loss: 294.9540367126465
Accuracy :
0.4375
Confusion matrix :
[[ 30  54  71]
 [ 16  29  52]
 [ 23  54 151]]
Accuracy low :
0.6583333333333333
Accuracy medium :
0.6333333333333333
Accuracy high :
0.5833333333333334
Average accuracy :
0.625
Classification report :
              precision    recall  f1-score   support

           0       0.43      0.19      0.27       155
           1       0.21      0.30      0.25        97
           2       0.55      0.66      0.60       228

    accuracy                           0.44       480
   macro avg       0.40      0.38      0.37       480
weighted avg       0.44      0.44      0.42       480

Fold1 - Test loss: 16.389
Fold1 - Test accuracy: 43.75%

Time 180.05 min
Fold2 - Train loss: 442.27446258068085
Accuracy :
0.35833333333333334
Confusion matrix :
[[ 18  78  59]
 [  8  47  42]
 [ 23  98 107]]
Accuracy low :
0.65
Accuracy medium :
0.5291666666666667
Accuracy high :
0.5375
Average accuracy :
0.5722222222222223
Classification report :
              precision    recall  f1-score   support

           0       0.37      0.12      0.18       155
           1       0.21      0.48      0.29        97
           2       0.51      0.47      0.49       228

    accuracy                           0.36       480
   macro avg       0.36      0.36      0.32       480
weighted avg       0.41      0.36      0.35       480

Fold2 - Test loss: 16.439
Fold2 - Test accuracy: 35.83%

Time 181.81 min
Fold3 - Train loss: 589.7263814210892
Accuracy :
0.4625
Confusion matrix :
[[ 59  45  51]
 [ 14  50  32]
 [ 24  92 113]]
Accuracy low :
0.7208333333333333
Accuracy medium :
0.61875
Accuracy high :
0.5854166666666667
Average accuracy :
0.6416666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.61      0.38      0.47       155
           1       0.27      0.52      0.35        96
           2       0.58      0.49      0.53       229

    accuracy                           0.46       480
   macro avg       0.48      0.46      0.45       480
weighted avg       0.52      0.46      0.48       480

Fold3 - Test loss: 16.391
Fold3 - Test accuracy: 46.25%

Time 183.82 min
Fold4 - Train loss: 737.2073044776917
Accuracy :
0.4375
Confusion matrix :
[[ 49  54  52]
 [ 21  34  41]
 [ 20  82 127]]
Accuracy low :
0.69375
Accuracy medium :
0.5875
Accuracy high :
0.59375
Average accuracy :
0.625
Classification report :
              precision    recall  f1-score   support

           0       0.54      0.32      0.40       155
           1       0.20      0.35      0.26        96
           2       0.58      0.55      0.57       229

    accuracy                           0.44       480
   macro avg       0.44      0.41      0.41       480
weighted avg       0.49      0.44      0.45       480

Fold4 - Test loss: 16.433
Fold4 - Test accuracy: 43.75%

Time 185.83 min
Fold5 - Train loss: 884.588608622551
Accuracy :
0.47708333333333336
Confusion matrix :
[[ 68  36  51]
 [ 23  33  40]
 [ 51  50 128]]
Accuracy low :
0.6645833333333333
Accuracy medium :
0.6895833333333333
Accuracy high :
0.6
Average accuracy :
0.6513888888888889
Classification report :
              precision    recall  f1-score   support

           0       0.48      0.44      0.46       155
           1       0.28      0.34      0.31        96
           2       0.58      0.56      0.57       229

    accuracy                           0.48       480
   macro avg       0.45      0.45      0.45       480
weighted avg       0.49      0.48      0.48       480

Fold5 - Test loss: 16.366
Fold5 - Test accuracy: 47.71%

Time 187.86 min
Fold6 - Train loss: 1031.9877643585205
Accuracy :
0.4666666666666667
Confusion matrix :
[[108  23  25]
 [ 43  18  35]
 [ 80  50  98]]
Accuracy low :
0.64375
Accuracy medium :
0.6854166666666667
Accuracy high :
0.6041666666666666
Average accuracy :
0.6444444444444444
Classification report :
              precision    recall  f1-score   support

           0       0.47      0.69      0.56       156
           1       0.20      0.19      0.19        96
           2       0.62      0.43      0.51       228

    accuracy                           0.47       480
   macro avg       0.43      0.44      0.42       480
weighted avg       0.49      0.47      0.46       480

Fold6 - Test loss: 16.483
Fold6 - Test accuracy: 46.67%

Time 189.72 min
Fold7 - Train loss: 1179.3334430456161
Accuracy :
0.34791666666666665
Confusion matrix :
[[82 38 36]
 [45 25 26]
 [91 77 60]]
Accuracy low :
0.5625
Accuracy medium :
0.6125
Accuracy high :
0.5208333333333334
Average accuracy :
0.5652777777777778
Classification report :
              precision    recall  f1-score   support

           0       0.38      0.53      0.44       156
           1       0.18      0.26      0.21        96
           2       0.49      0.26      0.34       228

    accuracy                           0.35       480
   macro avg       0.35      0.35      0.33       480
weighted avg       0.39      0.35      0.35       480

Fold7 - Test loss: 16.443
Fold7 - Test accuracy: 34.79%

Time 191.55 min
Fold8 - Train loss: 1326.716364979744
Accuracy :
0.47708333333333336
Confusion matrix :
[[ 66  31  59]
 [ 18  37  41]
 [ 46  56 126]]
Accuracy low :
0.6791666666666667
Accuracy medium :
0.6958333333333333
Accuracy high :
0.5791666666666667
Average accuracy :
0.6513888888888889
Classification report :
              precision    recall  f1-score   support

           0       0.51      0.42      0.46       156
           1       0.30      0.39      0.34        96
           2       0.56      0.55      0.56       228

    accuracy                           0.48       480
   macro avg       0.45      0.45      0.45       480
weighted avg       0.49      0.48      0.48       480

Fold8 - Test loss: 16.368
Fold8 - Test accuracy: 47.71%

Time 193.43 min
Fold9 - Train loss: 1474.0823112726212
Accuracy :
0.3875
Confusion matrix :
[[ 55  46  55]
 [ 35  24  37]
 [ 50  71 107]]
Accuracy low :
0.6125
Accuracy medium :
0.60625
Accuracy high :
0.55625
Average accuracy :
0.5916666666666667
Classification report :
              precision    recall  f1-score   support

           0       0.39      0.35      0.37       156
           1       0.17      0.25      0.20        96
           2       0.54      0.47      0.50       228

    accuracy                           0.39       480
   macro avg       0.37      0.36      0.36       480
weighted avg       0.42      0.39      0.40       480

Fold9 - Test loss: 16.367
Fold9 - Test accuracy: 38.75%

==================== BEST TEST ACCURACY =================================
0.50625
